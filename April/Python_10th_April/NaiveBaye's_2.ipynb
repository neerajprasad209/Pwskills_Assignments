{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center style = \"font-size:300%; font-style: italic;\">Assignment  64: Naive Bayes 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 : A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can solve this problem using Bayes' theorem. Let S be the event that an employee is a smoker, and H be the event that an employee uses the health insurance plan. We want to find the conditional probability P(S|H), i.e., the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
    "\n",
    "### From the information given in the problem, we know:\n",
    "\n",
    "~~~\n",
    "P(H) = 0.7, since 70% of the employees use the health insurance plan.\n",
    "\n",
    "P(S|H) = 0.4, since 40% of the employees who use the health insurance plan are smokers.\n",
    "~~~\n",
    "\n",
    "### Missing Information : Total percentage of smokers in organisation is not given\n",
    "\n",
    "~~~\n",
    "Assuming total number of smokers in the organisation to be 35%\n",
    "\n",
    "P(S) = 0.35\n",
    "~~~\n",
    "\n",
    "### Finding Probability that an employee is a smoker given that he/she uses the health insurance plan\n",
    "\n",
    "~~~\n",
    "P(H|S) = P(S|H)*P(H)/P(S)\n",
    "\n",
    "P(H|S) = 0.4*0.7/0.35\n",
    "\n",
    "P(H|S) = 0.8\n",
    "~~~\n",
    "\n",
    "### Hence Probability that an employee is smoker given that he/she uses health insurance plan is 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm, which is a probabilistic classification algorithm that is widely used in natural language processing, text mining, and other machine learning applications. Below are difference between Bernoullin and Multinomial Naive Bayes :\n",
    "\n",
    "| Bernoulli Naive Bayes | Multinomial Naive Bayes |\n",
    "|-----------------------|-------------------------|\n",
    "| Assumes binary input data | Assumes count input data |\n",
    "| Represents each document as a binary vector | Represents each document as a count vector |\n",
    "| Calculates likelihood probabilities based on presence/absence of features | Calculates likelihood probabilities based on frequency of features |\n",
    "| Suitable for problems focused on the presence or absence of features | Suitable for problems focused on the frequency of features |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 : How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Bernoulli Naive Bayes, missing data is typically handled by assigning a special value to indicate the absence of a feature. This value is often denoted as \"0\" and is used to represent the absence of a feature in a document.\n",
    "\n",
    "### During training, the algorithm learns the probabilities of each feature appearing in each class based on the available data. When a feature is missing from a document during classification, it is assumed to have the same probability of appearing in that class as it does in the training data.\n",
    "\n",
    "### Let's say we are classifying movie reviews as positive or negative based on the presence of certain words, and we have trained a Bernoulli Naive Bayes model on a dataset of labeled reviews. During training, we see that the word \"superb\" appears in 80% of positive reviews and in 5% of negative reviews. Based on this, the model learns to associate the presence of \"superb\" with the positive class.\n",
    "\n",
    "### Now, suppose we are given a new review that does not contain the word \"superb\". In this case, the model assumes that the probability of \"superb\" appearing in this review is 0, and calculates the probability of the review belonging to each class based on the other features that are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 : Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes, Gaussian Naive Bayes can be used for multi-class classification problems. In this case, the algorithm extends the binary Gaussian Naive Bayes classifier to the multi-class setting by using the \"one-vs-all\" (OvA) approach.\n",
    "\n",
    "### In the OvA approach, the multi-class problem is divided into multiple binary classification problems, with each class compared against all other classes. For example, if we have a problem with three classes (A, B, and C), we would train three binary classifiers: one to distinguish A from B and C, one to distinguish B from A and C, and one to distinguish C from A and B.\n",
    "\n",
    "### During classification, the algorithm calculates the probability of each document belonging to each class using the corresponding binary classifier. The document is assigned to the class with the highest probability.\n",
    "\n",
    "### In Gaussian Naive Bayes, the likelihood probability is modeled using a Gaussian distribution for each feature in each class. The algorithm estimates the mean and variance of each feature in each class based on the training data. During classification, the algorithm calculates the probability of each document belonging to each class using the Gaussian distribution parameters for that class.\n",
    "\n",
    "### Overall, Gaussian Naive Bayes can be a useful algorithm for multi-class classification problems when the features are continuous and can be modeled using a Gaussian distribution. However, it is important to note that it makes certain assumptions about the data (such as independence of features) that may not always hold in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 : Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation:\n",
    "\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Spambase](https://archive.ics.uci.edu/ml/datasets/Spambase).This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./spambase/spambase.names','r') as f:\n",
    "    a = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\n",
      "|\n",
      "| 48 continuous real [0,100] attributes of type word_freq_WORD \n",
      "| = percentage of words in the e-mail that match WORD,\n",
      "| i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
      "| total number of words in e-mail.  A \"word\" in this case is any \n",
      "| string of alphanumeric characters bounded by non-alphanumeric \n",
      "| characters or end-of-string.\n",
      "|\n",
      "| 6 continuous real [0,100] attributes of type char_freq_CHAR\n",
      "| = percentage of characters in the e-mail that match CHAR,\n",
      "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "|\n",
      "| 1 continuous real [1,...] attribute of type capital_run_length_average\n",
      "| = average length of uninterrupted sequences of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
      "| = length of longest uninterrupted sequence of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_total\n",
      "| = sum of length of uninterrupted sequences of capital letters\n",
      "| = total number of capital letters in the e-mail\n",
      "|\n",
      "| 1 nominal {0,1} class attribute of type spam\n",
      "| = denotes whether the e-mail was considered spam (1) or not (0), \n",
      "| i.e. unsolicited commercial e-mail.  \n",
      "|\n",
      "| For more information, see file 'spambase.DOCUMENTATION' at the\n",
      "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
      "\n",
      "\n",
      "1, 0.    | spam, non-spam classes\n",
      "\n",
      "word_freq_make:         continuous.\n",
      "word_freq_address:      continuous.\n",
      "word_freq_all:          continuous.\n",
      "word_freq_3d:           continuous.\n",
      "word_freq_our:          continuous.\n",
      "word_freq_over:         continuous.\n",
      "word_freq_remove:       continuous.\n",
      "word_freq_internet:     continuous.\n",
      "word_freq_order:        continuous.\n",
      "word_freq_mail:         continuous.\n",
      "word_freq_receive:      continuous.\n",
      "word_freq_will:         continuous.\n",
      "word_freq_people:       continuous.\n",
      "word_freq_report:       continuous.\n",
      "word_freq_addresses:    continuous.\n",
      "word_freq_free:         continuous.\n",
      "word_freq_business:     continuous.\n",
      "word_freq_email:        continuous.\n",
      "word_freq_you:          continuous.\n",
      "word_freq_credit:       continuous.\n",
      "word_freq_your:         continuous.\n",
      "word_freq_font:         continuous.\n",
      "word_freq_000:          continuous.\n",
      "word_freq_money:        continuous.\n",
      "word_freq_hp:           continuous.\n",
      "word_freq_hpl:          continuous.\n",
      "word_freq_george:       continuous.\n",
      "word_freq_650:          continuous.\n",
      "word_freq_lab:          continuous.\n",
      "word_freq_labs:         continuous.\n",
      "word_freq_telnet:       continuous.\n",
      "word_freq_857:          continuous.\n",
      "word_freq_data:         continuous.\n",
      "word_freq_415:          continuous.\n",
      "word_freq_85:           continuous.\n",
      "word_freq_technology:   continuous.\n",
      "word_freq_1999:         continuous.\n",
      "word_freq_parts:        continuous.\n",
      "word_freq_pm:           continuous.\n",
      "word_freq_direct:       continuous.\n",
      "word_freq_cs:           continuous.\n",
      "word_freq_meeting:      continuous.\n",
      "word_freq_original:     continuous.\n",
      "word_freq_project:      continuous.\n",
      "word_freq_re:           continuous.\n",
      "word_freq_edu:          continuous.\n",
      "word_freq_table:        continuous.\n",
      "word_freq_conference:   continuous.\n",
      "char_freq_;:            continuous.\n",
      "char_freq_(:            continuous.\n",
      "char_freq_[:            continuous.\n",
      "char_freq_!:            continuous.\n",
      "char_freq_$:            continuous.\n",
      "char_freq_#:            continuous.\n",
      "capital_run_length_average: continuous.\n",
      "capital_run_length_longest: continuous.\n",
      "capital_run_length_total:   continuous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./spambase/spambase.DOCUMENTATION','r') as f1:\n",
    "    b = f1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title:  SPAM E-mail Database\n",
      "\n",
      "2. Sources:\n",
      "   (a) Creators: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\n",
      "        Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\n",
      "   (b) Donor: George Forman (gforman at nospam hpl.hp.com)  650-857-7835\n",
      "   (c) Generated: June-July 1999\n",
      "\n",
      "3. Past Usage:\n",
      "   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\n",
      "   (b) Determine whether a given email is spam or not.\n",
      "   (c) ~7% misclassification error.\n",
      "       False positives (marking good mail as spam) are very undesirable.\n",
      "       If we insist on zero false positives in the training/testing set,\n",
      "       20-25% of the spam passed through the filter.\n",
      "\n",
      "4. Relevant Information:\n",
      "        The \"spam\" concept is diverse: advertisements for products/web\n",
      "        sites, make money fast schemes, chain letters, pornography...\n",
      "\tOur collection of spam e-mails came from our postmaster and \n",
      "\tindividuals who had filed spam.  Our collection of non-spam \n",
      "\te-mails came from filed work and personal e-mails, and hence\n",
      "\tthe word 'george' and the area code '650' are indicators of \n",
      "\tnon-spam.  These are useful when constructing a personalized \n",
      "\tspam filter.  One would either have to blind such non-spam \n",
      "\tindicators or get a very wide collection of non-spam to \n",
      "\tgenerate a general purpose spam filter.\n",
      "\n",
      "        For background on spam:\n",
      "        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \n",
      "        Communications of the ACM, 41(8):74-83, 1998.\n",
      "\n",
      "5. Number of Instances: 4601 (1813 Spam = 39.4%)\n",
      "\n",
      "6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\n",
      "\n",
      "7. Attribute Information:\n",
      "The last column of 'spambase.data' denotes whether the e-mail was \n",
      "considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \n",
      "Most of the attributes indicate whether a particular word or\n",
      "character was frequently occuring in the e-mail.  The run-length\n",
      "attributes (55-57) measure the length of sequences of consecutive \n",
      "capital letters.  For the statistical measures of each attribute, \n",
      "see the end of this file.  Here are the definitions of the attributes:\n",
      "\n",
      "48 continuous real [0,100] attributes of type word_freq_WORD \n",
      "= percentage of words in the e-mail that match WORD,\n",
      "i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
      "total number of words in e-mail.  A \"word\" in this case is any \n",
      "string of alphanumeric characters bounded by non-alphanumeric \n",
      "characters or end-of-string.\n",
      "\n",
      "6 continuous real [0,100] attributes of type char_freq_CHAR\n",
      "= percentage of characters in the e-mail that match CHAR,\n",
      "i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "\n",
      "1 continuous real [1,...] attribute of type capital_run_length_average\n",
      "= average length of uninterrupted sequences of capital letters\n",
      "\n",
      "1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
      "= length of longest uninterrupted sequence of capital letters\n",
      "\n",
      "1 continuous integer [1,...] attribute of type capital_run_length_total\n",
      "= sum of length of uninterrupted sequences of capital letters\n",
      "= total number of capital letters in the e-mail\n",
      "\n",
      "1 nominal {0,1} class attribute of type spam\n",
      "= denotes whether the e-mail was considered spam (1) or not (0), \n",
      "i.e. unsolicited commercial e-mail.  \n",
      "\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      "\n",
      "9. Class Distribution:\n",
      "\tSpam\t  1813  (39.4%)\n",
      "\tNon-Spam  2788  (60.6%)\n",
      "\n",
      "\n",
      "Attribute Statistics:\n",
      "   Min: Max:   Average:  Std.Dev: Coeff.Var_%: \n",
      "1  0    4.54   0.10455   0.30536  292          \n",
      "2  0    14.28  0.21301   1.2906   606          \n",
      "3  0    5.1    0.28066   0.50414  180          \n",
      "4  0    42.81  0.065425  1.3952   2130         \n",
      "5  0    10     0.31222   0.67251  215          \n",
      "6  0    5.88   0.095901  0.27382  286          \n",
      "7  0    7.27   0.11421   0.39144  343          \n",
      "8  0    11.11  0.10529   0.40107  381          \n",
      "9  0    5.26   0.090067  0.27862  309          \n",
      "10 0    18.18  0.23941   0.64476  269          \n",
      "11 0    2.61   0.059824  0.20154  337          \n",
      "12 0    9.67   0.5417    0.8617   159          \n",
      "13 0    5.55   0.09393   0.30104  320          \n",
      "14 0    10     0.058626  0.33518  572          \n",
      "15 0    4.41   0.049205  0.25884  526          \n",
      "16 0    20     0.24885   0.82579  332          \n",
      "17 0    7.14   0.14259   0.44406  311          \n",
      "18 0    9.09   0.18474   0.53112  287          \n",
      "19 0    18.75  1.6621    1.7755   107          \n",
      "20 0    18.18  0.085577  0.50977  596          \n",
      "21 0    11.11  0.80976   1.2008   148          \n",
      "22 0    17.1   0.1212    1.0258   846          \n",
      "23 0    5.45   0.10165   0.35029  345          \n",
      "24 0    12.5   0.094269  0.44264  470          \n",
      "25 0    20.83  0.5495    1.6713   304          \n",
      "26 0    16.66  0.26538   0.88696  334          \n",
      "27 0    33.33  0.7673    3.3673   439          \n",
      "28 0    9.09   0.12484   0.53858  431          \n",
      "29 0    14.28  0.098915  0.59333  600          \n",
      "30 0    5.88   0.10285   0.45668  444          \n",
      "31 0    12.5   0.064753  0.40339  623          \n",
      "32 0    4.76   0.047048  0.32856  698          \n",
      "33 0    18.18  0.097229  0.55591  572          \n",
      "34 0    4.76   0.047835  0.32945  689          \n",
      "35 0    20     0.10541   0.53226  505          \n",
      "36 0    7.69   0.097477  0.40262  413          \n",
      "37 0    6.89   0.13695   0.42345  309          \n",
      "38 0    8.33   0.013201  0.22065  1670         \n",
      "39 0    11.11  0.078629  0.43467  553          \n",
      "40 0    4.76   0.064834  0.34992  540          \n",
      "41 0    7.14   0.043667  0.3612   827          \n",
      "42 0    14.28  0.13234   0.76682  579          \n",
      "43 0    3.57   0.046099  0.22381  486          \n",
      "44 0    20     0.079196  0.62198  785          \n",
      "45 0    21.42  0.30122   1.0117   336          \n",
      "46 0    22.05  0.17982   0.91112  507          \n",
      "47 0    2.17   0.0054445 0.076274 1400         \n",
      "48 0    10     0.031869  0.28573  897          \n",
      "49 0    4.385  0.038575  0.24347  631          \n",
      "50 0    9.752  0.13903   0.27036  194          \n",
      "51 0    4.081  0.016976  0.10939  644          \n",
      "52 0    32.478 0.26907   0.81567  303          \n",
      "53 0    6.003  0.075811  0.24588  324          \n",
      "54 0    19.829 0.044238  0.42934  971          \n",
      "55 1    1102.5 5.1915    31.729   611          \n",
      "56 1    9989   52.173    194.89   374          \n",
      "57 1    15841  283.29    606.35   214          \n",
      "58 0    1      0.39404   0.4887   124          \n",
      "\n",
      "\n",
      "This file: 'spambase.DOCUMENTATION' at the UCI Machine Learning Repository\n",
      "http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./spambase/spambase.data',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "for i in range(df.shape[1]):\n",
    "    if i!=57:\n",
    "        fs = 'f'+str(i+1)\n",
    "        features.append(fs)\n",
    "    else:\n",
    "        features.append('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1    f2    f3   f4    f5    f6    f7    f8    f9   f10  ...   f49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "     f50  f51    f52    f53    f54    f55  f56   f57  target  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278       1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028       1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259       1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191       1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191       1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    2788\n",
       "1    1813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1        0\n",
       "f2        0\n",
       "f3        0\n",
       "f4        0\n",
       "f5        0\n",
       "f6        0\n",
       "f7        0\n",
       "f8        0\n",
       "f9        0\n",
       "f10       0\n",
       "f11       0\n",
       "f12       0\n",
       "f13       0\n",
       "f14       0\n",
       "f15       0\n",
       "f16       0\n",
       "f17       0\n",
       "f18       0\n",
       "f19       0\n",
       "f20       0\n",
       "f21       0\n",
       "f22       0\n",
       "f23       0\n",
       "f24       0\n",
       "f25       0\n",
       "f26       0\n",
       "f27       0\n",
       "f28       0\n",
       "f29       0\n",
       "f30       0\n",
       "f31       0\n",
       "f32       0\n",
       "f33       0\n",
       "f34       0\n",
       "f35       0\n",
       "f36       0\n",
       "f37       0\n",
       "f38       0\n",
       "f39       0\n",
       "f40       0\n",
       "f41       0\n",
       "f42       0\n",
       "f43       0\n",
       "f44       0\n",
       "f45       0\n",
       "f46       0\n",
       "f47       0\n",
       "f48       0\n",
       "f49       0\n",
       "f50       0\n",
       "f51       0\n",
       "f52       0\n",
       "f53       0\n",
       "f54       0\n",
       "f55       0\n",
       "f56       0\n",
       "f57       0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:\n",
    "\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating X and Y variables\n",
    "X = df.drop(labels=['target'],axis=1)\n",
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y,test_size=0.3,random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(xtrain,ytrain.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf =  StratifiedKFold(n_splits=10,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77564103, 0.82191781, 0.80267559, 0.802589  , 0.78064516,\n",
       "       0.81081081, 0.82876712, 0.82033898, 0.80130293, 0.8125    ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_gnb = cross_val_score(GaussianNB(),xtrain,ytrain.values.flatten(),cv=skf,scoring='f1')\n",
    "scores_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Gaussian Naive Bayes\n",
      "Mean 10 fold cross validation f1 score is : 0.8057\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mean_score_gnb = np.mean(scores_gnb)\n",
    "print('Results for Gaussian Naive Bayes')\n",
    "print(f'Mean 10 fold cross validation f1 score is : {mean_score_gnb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(xtrain,ytrain.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84897959, 0.84677419, 0.84120172, 0.8515625 , 0.85258964,\n",
       "       0.81512605, 0.8879668 , 0.85232068, 0.85483871, 0.84081633])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_bnb = cross_val_score(BernoulliNB(),xtrain,ytrain.values.flatten(),cv=skf,scoring='f1')\n",
    "scores_bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BernoulliNB :\n",
      "Mean 10 fold cross validation f1 score is : 0.8492\n"
     ]
    }
   ],
   "source": [
    "mean_score_bnb = np.mean(scores_bnb)\n",
    "print('Results for BernoulliNB :')\n",
    "print(f'Mean 10 fold cross validation f1 score is : {mean_score_bnb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain,ytrain.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70817121, 0.68907563, 0.74509804, 0.71604938, 0.67741935,\n",
       "       0.72131148, 0.76      , 0.712     , 0.703125  , 0.7768595 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_mnb = cross_val_score(MultinomialNB(),xtrain,ytrain.values.flatten(),cv=skf,scoring='f1')\n",
    "scores_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for MultinomialNB :\n",
      "Mean 10 fold cross validation f1 score is : 0.7209\n"
     ]
    }
   ],
   "source": [
    "mean_score_mnb = np.mean(scores_mnb)\n",
    "print('Results for MultinomialNB :')\n",
    "print(f'Mean 10 fold cross validation f1 score is : {mean_score_mnb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes provided Highest training cross validation score of 0.8492 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: \n",
    "\n",
    "Report the following performance metrics for each classifier:\n",
    "\n",
    "* Accuracy\n",
    "\n",
    "* Precision\n",
    "\n",
    "* Recall\n",
    "\n",
    "* F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to store all above metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def evaluate_model(x,y,model):\n",
    "    ypred = model.predict(x)\n",
    "    acc = accuracy_score(y,ypred)\n",
    "    pre = precision_score(y,ypred)\n",
    "    rec = recall_score(y,ypred)\n",
    "    f1 = f1_score(y,ypred)\n",
    "    print(f'Accuracy  : {acc:.4f}')\n",
    "    print(f'Precision : {pre:.4f}')\n",
    "    print(f'Recall    : {rec:.4f}')\n",
    "    print(f'F1 Score  : {f1:.4f}')\n",
    "    return acc, pre, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Results : \n",
      "\n",
      "Accuracy  : 0.8240\n",
      "Precision : 0.7048\n",
      "Recall    : 0.9522\n",
      "F1 Score  : 0.8100\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes Results : \\n')\n",
    "acc_gnb, pre_gnb, rec_gnb, f1_gnb = evaluate_model(xtest,ytest.values.flatten(),gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Results : \n",
      "\n",
      "Accuracy  : 0.8870\n",
      "Precision : 0.8865\n",
      "Recall    : 0.8180\n",
      "F1 Score  : 0.8509\n"
     ]
    }
   ],
   "source": [
    "print('Bernoulli Naive Bayes Results : \\n')\n",
    "acc_bnb, pre_bnb, rec_bnb, f1_bnb = evaluate_model(xtest,ytest.values.flatten(),bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Results : \n",
      "\n",
      "Accuracy  : 0.7697\n",
      "Precision : 0.7190\n",
      "Recall    : 0.6820\n",
      "F1 Score  : 0.7000\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial Naive Bayes Results : \\n')\n",
    "acc_mnb, pre_mnb, rec_mnb, f1_mnb = evaluate_model(xtest,ytest.values.flatten(),mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for dataframe\n",
    "dct = {\n",
    "    'score':['accuracy','precision','recall','f1'],\n",
    "    'Gaussian':[acc_gnb,pre_gnb,rec_gnb,f1_gnb],\n",
    "    'Bernoulli':[acc_bnb,pre_bnb,rec_bnb,f1_bnb],\n",
    "    'Multinomial':[acc_mnb,pre_mnb,rec_mnb,f1_mnb]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>Gaussian</th>\n",
       "      <th>Bernoulli</th>\n",
       "      <th>Multinomial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.824041</td>\n",
       "      <td>0.887038</td>\n",
       "      <td>0.769732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.886454</td>\n",
       "      <td>0.718992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.952206</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.681985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.810008</td>\n",
       "      <td>0.850860</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  Gaussian  Bernoulli  Multinomial\n",
       "0   accuracy  0.824041   0.887038     0.769732\n",
       "1  precision  0.704762   0.886454     0.718992\n",
       "2     recall  0.952206   0.818015     0.681985\n",
       "3         f1  0.810008   0.850860     0.700000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "df_compare = pd.DataFrame(dct)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_crossval = {\n",
    "    'models':['Gaussian','Bernoulli','Multinomial'],\n",
    "    'cross_val_score_mean':[mean_score_gnb,mean_score_bnb,mean_score_mnb]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cross_val_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.805719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>0.849218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.720911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        models  cross_val_score_mean\n",
       "0     Gaussian              0.805719\n",
       "1    Bernoulli              0.849218\n",
       "2  Multinomial              0.720911"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crossval = pd.DataFrame(dct_crossval)\n",
    "df_crossval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model for above data is `Bernoulli Naive Bayes`\n",
    "Bernoulli Naive Bayes is best model because of below reasons :\n",
    "1. BernoulliNB has highest test f1 score of 0.8509\n",
    "2. BernoulliNB has highest test accuracy of 0.8870\n",
    "3. BernoulliNB has highest 10 fold cross validation F1 score of 0.8492"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Although Naive Bayes algorithm is a powerful and widely used algorithm, it also has some limitations, including:\n",
    "\n",
    "1. The assumption of feature independence: The Naive Bayes algorithm assumes that the features are independent of each other. However, in real-world scenarios, this assumption is not always true, and features may be dependent on each other.\n",
    "\n",
    "2. Sensitivity to input data: Naive Bayes algorithm is very sensitive to input data, and even a slight change in the input data can significantly affect the accuracy of the model.\n",
    "\n",
    "3. Lack of tuning parameters: Naive Bayes algorithm does not have many tuning parameters that can be adjusted to improve its performance.\n",
    "\n",
    "4. Data sparsity problem: Naive Bayes algorithm relies on a lot of training data to estimate the probabilities of different features. However, if some features have very low frequencies in the training data, the algorithm may not be able to accurately estimate their probabilities.\n",
    "\n",
    "5. Class-conditional independence assumption: Naive Bayes algorithm assumes that each feature is conditionally independent given the class. However, in many cases, this assumption may not hold, and the algorithm may not perform well.\n",
    "\n",
    "6. Imbalanced class distribution: Naive Bayes algorithm assumes that the classes are equally likely, but in real-world scenarios, the class distribution may be imbalanced, which can lead to biased results.\n",
    "\n",
    "7. The need for continuous data: Naive Bayes algorithm assumes that the input features are continuous, which may not always be the case in real-world scenarios where the input features are discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are conclusions for above model\n",
    "1. Bernoulli Naive Bayes performed best on both cross validation and test dataset.\n",
    "2. For Email Classification Neural Network is better suited algorithm as it is able to provide better results and has lot of tunable paramenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the BernoulliNB file to pickle for future use\n",
    "import pickle\n",
    "with open('BernoulliModel.pkl','wb') as f:\n",
    "    pickle.dump(bnb,file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
